{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treino do Recomendador Simples de Ações\n",
        "\n",
        "Executar este notebook gera os artefatos em `artifacts/` para a API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "..//artifacts\n"
          ]
        }
      ],
      "source": [
        "import os, json, math, time, datetime as dt\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from joblib import dump\n",
        "\n",
        "BASE = '../'\n",
        "ART = f\"{BASE}/artifacts\"\n",
        "os.makedirs(ART, exist_ok=True)\n",
        "\n",
        "US_TICKERS = [\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"NVDA\",\"TSLA\",\"JPM\",\"V\",\"PG\",\"KO\",\"PEP\",\"NFLX\",\"AMD\",\"INTC\",\"DIS\"]\n",
        "BR_TICKERS = [\"PETR4.SA\",\"VALE3.SA\",\"ITUB4.SA\",\"BBDC4.SA\",\"ABEV3.SA\",\"WEGE3.SA\",\"BBAS3.SA\",\"B3SA3.SA\",\"RAIL3.SA\",\"PRIO3.SA\",\"LREN3.SA\",\"GGBR4.SA\"]\n",
        "TICKERS = US_TICKERS + BR_TICKERS\n",
        "\n",
        "def region_for(t):\n",
        "    return \"BR\" if t.endswith(\".SA\") else \"US\"\n",
        "\n",
        "def _normalize_ohlcv(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df is None or df.empty:\n",
        "        return pd.DataFrame()\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(-1)\n",
        "    df = df.rename(columns={c: c.strip() for c in df.columns})\n",
        "    if \"Close\" not in df.columns:\n",
        "        if \"Adj Close\" in df.columns:\n",
        "            df[\"Close\"] = df[\"Adj Close\"]\n",
        "        else:\n",
        "            return pd.DataFrame()\n",
        "    if \"Volume\" not in df.columns:\n",
        "        df[\"Volume\"] = np.nan\n",
        "    keep = [c for c in [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"] if c in df.columns]\n",
        "    return df[keep].copy()\n",
        "\n",
        "def _reset_index_naive_utc(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    idx = df.index\n",
        "    if hasattr(idx, \"tz\") and idx.tz is not None:\n",
        "        df.index = idx.tz_convert(\"UTC\").tz_localize(None)\n",
        "    df = df.reset_index()\n",
        "    date_col = \"Date\" if \"Date\" in df.columns else df.columns[0]\n",
        "    df = df.rename(columns={date_col: \"date\"})\n",
        "    return df\n",
        "\n",
        "def fetch_single(ticker: str, start: dt.date, end: dt.date, interval=\"1d\", tries=3, sleep_s=0.6) -> pd.DataFrame:\n",
        "    for _ in range(tries):\n",
        "        try:\n",
        "            t = yf.Ticker(ticker)\n",
        "            df = t.history(start=start, end=end, interval=interval, auto_adjust=False, actions=False, repair=True)\n",
        "            df = _normalize_ohlcv(df)\n",
        "            if not df.empty:\n",
        "                df = _reset_index_naive_utc(df)\n",
        "                df[\"ticker\"] = ticker\n",
        "                return df\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(sleep_s)\n",
        "    try:\n",
        "        df = yf.download(ticker, period=\"1y\", interval=interval, auto_adjust=False, progress=False)\n",
        "        df = _normalize_ohlcv(df)\n",
        "        if not df.empty:\n",
        "            df = _reset_index_naive_utc(df)\n",
        "            df[\"ticker\"] = ticker\n",
        "            return df\n",
        "    except Exception:\n",
        "        pass\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def fetch_history(tickers, period_days=420, interval=\"1d\"):\n",
        "    end = dt.date.today()\n",
        "    start = end - dt.timedelta(days=period_days)\n",
        "    frames = []\n",
        "    for t in tickers:\n",
        "        df = fetch_single(t, start=start, end=end, interval=interval)\n",
        "        if not df.empty:\n",
        "            frames.append(df)\n",
        "    if not frames:\n",
        "        return pd.DataFrame()\n",
        "    out = pd.concat(frames, ignore_index=True)\n",
        "    if \"Volume\" not in out.columns:\n",
        "        out[\"Volume\"] = 0.0\n",
        "    else:\n",
        "        out[\"Volume\"] = out[\"Volume\"].fillna(0.0)\n",
        "    out = out.dropna(subset=[\"Close\"])\n",
        "    out[\"date\"] = pd.to_datetime(out[\"date\"], utc=False, errors=\"coerce\")\n",
        "    out = out.dropna(subset=[\"date\"])\n",
        "    return out\n",
        "\n",
        "def compute_features(df):\n",
        "    dfs = []\n",
        "    for t, g in df.groupby(\"ticker\"):\n",
        "        g = g.sort_values(\"date\").copy()\n",
        "        g[\"ret_1d\"] = g[\"Close\"].pct_change()\n",
        "        g[\"ret_1m\"] = g[\"Close\"].pct_change(21)\n",
        "        g[\"ret_3m\"] = g[\"Close\"].pct_change(63)\n",
        "        g[\"ret_6m\"] = g[\"Close\"].pct_change(126)\n",
        "        g[\"vol_21\"] = g[\"ret_1d\"].rolling(21).std().fillna(0.0)\n",
        "        g[\"vol_63\"] = g[\"ret_1d\"].rolling(63).std().fillna(0.0)\n",
        "        g[\"volavg_21\"] = g[\"Volume\"].rolling(21).mean().bfill().fillna(0.0)\n",
        "        g[\"volavg_63\"] = g[\"Volume\"].rolling(63).mean().bfill().fillna(0.0)\n",
        "        last = g.iloc[-1:][[\"ticker\",\"ret_1m\",\"ret_3m\",\"ret_6m\",\"vol_21\",\"vol_63\",\"volavg_21\",\"volavg_63\",\"Close\"]].copy()\n",
        "        dfs.append(last)\n",
        "    if not dfs:\n",
        "        return pd.DataFrame()\n",
        "    feat = pd.concat(dfs, ignore_index=True)\n",
        "    return feat\n",
        "\n",
        "def fetch_meta(ticker: str):\n",
        "    name, sector = ticker, \"Desconhecido\"\n",
        "    try:\n",
        "        info = yf.Ticker(ticker).info\n",
        "        name = info.get(\"shortName\") or info.get(\"longName\") or ticker\n",
        "        sector = info.get(\"sector\") or \"Desconhecido\"\n",
        "    except Exception:\n",
        "        try:\n",
        "            fast = yf.Ticker(ticker).fast_info\n",
        "            name = str(fast.get(\"shortName\") or fast.get(\"longName\") or ticker)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return {\"ticker\": ticker, \"name\": name, \"setor\": sector}\n",
        "\n",
        "def label_vol(q):\n",
        "    if q <= 0.33:\n",
        "        return \"baixa\"\n",
        "    if q >= 0.66:\n",
        "        return \"alta\"\n",
        "    return \"media\"\n",
        "\n",
        "def label_liq(q):\n",
        "    if q <= 0.33:\n",
        "        return \"baixa\"\n",
        "    if q >= 0.66:\n",
        "        return \"alta\"\n",
        "    return \"media\"\n",
        "\n",
        "def label_trend(x):\n",
        "    if x > 0.03:\n",
        "        return \"alta\"\n",
        "    if x < -0.03:\n",
        "        return \"baixa\"\n",
        "    return \"estavel\"\n",
        "\n",
        "raw = fetch_history(TICKERS, period_days=420, interval=\"1d\")\n",
        "if raw.empty:\n",
        "    raise RuntimeError(\"Sem dados baixados. Teste rede ou reduza TICKERS para ['AAPL','MSFT'] temporariamente.\")\n",
        "raw[\"date\"] = pd.to_datetime(raw[\"date\"], utc=False, errors=\"coerce\")\n",
        "raw = raw.dropna(subset=[\"date\"])\n",
        "feat = compute_features(raw)\n",
        "if feat.empty:\n",
        "    raise RuntimeError(\"Sem features calculadas.\")\n",
        "feat[\"pais\"] = feat[\"ticker\"].apply(region_for)\n",
        "meta_rows = [fetch_meta(t) for t in feat[\"ticker\"]]\n",
        "meta = pd.DataFrame(meta_rows)\n",
        "df = feat.merge(meta, on=\"ticker\", how=\"left\")\n",
        "feature_cols = [\"ret_1m\",\"ret_3m\",\"ret_6m\",\"vol_21\",\"vol_63\",\"volavg_21\",\"volavg_63\"]\n",
        "X = df[feature_cols].fillna(0.0).replace([np.inf,-np.inf],0.0)\n",
        "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"kmeans\", KMeans(n_clusters=3, n_init=10, random_state=42))])\n",
        "pipe.fit(X)\n",
        "df[\"cluster\"] = pipe.named_steps[\"kmeans\"].labels_\n",
        "cluster_stats = df.groupby(\"cluster\")[\"vol_63\"].mean().sort_values().reset_index()\n",
        "order = cluster_stats[\"cluster\"].tolist()\n",
        "cluster_to_profile = {}\n",
        "if len(order) == 3:\n",
        "    cluster_to_profile[order[0]] = \"Conservador\"\n",
        "    cluster_to_profile[order[1]] = \"Equilibrado\"\n",
        "    cluster_to_profile[order[2]] = \"Ousado\"\n",
        "else:\n",
        "    for i, c in enumerate(order):\n",
        "        cluster_to_profile[c] = f\"Grupo {i+1}\"\n",
        "df[\"perfil_cluster\"] = df[\"cluster\"].map(cluster_to_profile)\n",
        "v_quant = df[\"vol_63\"].rank(pct=True)\n",
        "l_quant = df[\"volavg_21\"].rank(pct=True)\n",
        "df[\"vol_label\"] = v_quant.apply(label_vol)\n",
        "df[\"liq_label\"] = l_quant.apply(label_liq)\n",
        "df[\"trend_label\"] = df[\"ret_1m\"].apply(label_trend)\n",
        "final_cols = [\"ticker\",\"name\",\"setor\",\"pais\",\"ret_1m\",\"ret_3m\",\"ret_6m\",\"vol_21\",\"vol_63\",\"volavg_21\",\"volavg_63\",\"perfil_cluster\",\"vol_label\",\"liq_label\",\"trend_label\"]\n",
        "universe = df[final_cols].copy()\n",
        "universe.to_csv(f\"{ART}/universe.csv\", index=False)\n",
        "with open(f\"{ART}/feature_cols.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(feature_cols, f, ensure_ascii=False, indent=2)\n",
        "with open(f\"{ART}/cluster_map.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({str(k): v for k, v in cluster_to_profile.items()}, f, ensure_ascii=False, indent=2)\n",
        "dump(pipe, f\"{ART}/model.joblib\")\n",
        "print(str(ART))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3819c963",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
